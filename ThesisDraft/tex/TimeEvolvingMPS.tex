\chapter{Performing Time Evolution of Matrix Product States}
A central component of Optimal Control is time evolution. In order to compute any optimal control sequence, it is crucial to have a fast and accurate time evolution algorithm. However, also the construction of the time evolution operator must be taken into account, as exponentiating a tensor spanning the entire system, such as most Hamiltonians, is no easy task. In fact, since the time evolution operator is constantly altered when optimizing control parameters, the time spent exponentiating the Hamiltonian must be taken into account of the total runtime. Thus, both an efficient time evolution algorithm and an efficient operator exponentiation is needed when performing optimal control.\\
Several algorithms for time evolving matrix product states exist, however, they all origin from the same ideas proposed in \cite{Vidal2003,Vidal2004}. The most widely used of these algorithms is the tDMRG algorithm, which gets its name from its similarity with the ground state search algorithm described in Section \ref{sec:DMRG}. The tDMRG algorithm has been utilized in several instances to simulate the dynamics of one-dimensional systems CITE, and it has even been previously used in conjunction with the CRAB algorithm to perform optimal control of the Superfluid to Mott-Insulator phase transition \cite{FrankBloch,Doria2011}.\\
Although the standard algorithms for time evolution are quite efficient, further improvements can be made to the algorithms when tailoring to the problem at hand. Therefore, a modified version of the tDMRG algorithm is proposed in Section \ref{sec:modTMDRG}, which directly utilizes the properties of the Bose-Hubbard Hamiltonian.


\section{The tDMRG Algorithm}
Consider the time evolution of a quantum state
\begin{equation}
	\ket{\psi (t)} = \hat{\mathcal{U}}(t) \ket{\psi (0)} \; ,
\end{equation}
where $\hat{\mathcal{U}}(t) = \e^{ - \im \hat{H} t }$ is the time evolution operator. 
Time evolution of a matrix product states is done in a manner similar to that of ground state search, as the bonds between the tensors are evolved rather than the tensors themselves. Thus, the time evolution operator must be decomposed into two-site tensors. The simplest realisation of this is achieved, when considering a Hamiltonian containing only nearest-neighbour interactions.
Assume the Hamiltonian is a sum of two-site operators of the form $\hat{H} = \sum_{n} \hat{h}^{[n , n+1]}$. One can decompose this into a sum over even and odd bonds
\begin{equation}
	\hat{H} = \hat{H}_{\mathrm{odd}} \; + \; \hat{H}_{\mathrm{even}} = \sum_{n \; \mathrm{odd}} \hat{h}^{[n , n+1]} \; + \; \sum_{n \; \mathrm{even}} \hat{h}^{[n , n+1]} \; .
\end{equation}  
Exponentiating the Hamiltonian is non-trivial due to the non-commutativity of the operators, $[ \hat{h}_{\mathrm{odd}}^{[n , n+1]} \; , \; \hat{h}_{\mathrm{even}}^{[n , n+1]} ] \neq 0$. Considering a small time slice, $\delta t$, the exponentiation can be achieved through the Trotter-Suzuki expansion \cite{Suzuki}. To first order this reads
\begin{equation}
	\e^{- \im \hat{H} \; \Delta t} = \e^{- \im \hat{H}_{\mathrm{odd}} \; \Delta t } \e^{- \im \hat{H}_{\mathrm{even}} \; \Delta t} \; + \; \;  \mathrm{O}(\Delta t^2) \; ,
\end{equation}
where the error is due to the non-commutativity of the bond Hamiltonians. Thus, the time evolution operator can be expressed as the product
\begin{equation}
	\hat{\mathcal{U}}(\Delta t) \approx \left( \prod_{n \; \mathrm{odd}} \hat{\mathcal{U}}^{[n,n+1]} (\Delta t) \right) \left( \prod_{n \; \mathrm{even}} \hat{\mathcal{U}}^{[n,n+1]} (\Delta t) \right) \; ,
\end{equation}
where
\begin{equation}
	\hat{\mathcal{U}}^{[n,n+1]} (\Delta t) = \e^{- \im \hat{h}^{[n , n+1]} \; \Delta t } \; .
\end{equation}
The result is an MPO performing an infinitesimal time step on the odd bonds, and another MPO evolving the even bonds. An illustration of this is shown in Figure \ref{fig:oddevenops}.
\begin{figure}[h!]
	\centering
	\input{Diagrams/TEBD.tex}
	\caption{\textit{Approximation of each time step $\delta t$ using a Trotter-Suzuki decomposition, such that the time evolution operator is expressed as a product of unitary two-site operators.}}
	\label{fig:oddevenops}
\end{figure}
The tDMRG algorithm describes the most efficient and accurate way of contracting the tensor network detailed in Figure \ref{fig:oddevenops}. The algorithm gets its name from its similarity with the DMRG algorithm detailed in Section \ref{sec:DMRG}. In fact, the merge and unmerge procedure of the two algorithms is completely identical, whereby they only differ in the steps of applying the operator and proceeding to the next site. The following procedure details a time evolution step of the $n$'th bond \cite{schollwock}.

\subsection{Infinitesimal time-step update for tDMRG}
\begin{enumerate}
\item
\textbf{Merge:} Contract tensors $M^{[n]}$ and $M^{[n+1]}$ over the bond $\alpha_{n}$ creating a two-site tensor $\Theta^{j_n , j_{n+1}}$.

\item
\textbf{Apply unitary:} The two-site time evolution operator, $\hat{\mathcal{U}}^{[n, n+1]}$, is applied to $\Theta^{j_n , j_{n+1}}$
\begin{equation}
	\tilde{\Theta}_{\alpha_{n-1} , \alpha_{n+1}}^{j_n , j_{n+1} } = \sum_{j_n ', j_{n+1}'} U^{j_n  j_{n+1} , j_n '  j_{n+1}'} \; \Phi_{\alpha_{n-1} , \alpha_{n+1}}^{j_n ', j_{n+1} ' } \; .
\end{equation}

\item
\textbf{Unmerge:} Reshape $\tilde{\Phi}_{\alpha_{n-1} , \alpha_{n+1}}^{j_n ', j_{n+1} '}$ to a matrix and decompose it through an SVD. Applying $\hat{\mathcal{U}}^{[n, n+1]}$ causes an increase in bond dimension, $D \rightarrow d^2 D$, which must be truncated by keeping only the $D$ largest singular values from the SVD. 

\item
\textbf{Progress:}  Next, the center cite of the MPS must be shifted by two, in order to update the next even (odd) bond. This is achieved by merging tensors $M^{[n+1]}$ and $M^{[n+2]}$ and performing a second SVD, while reshaping the resulting $U$-matrices to left-normalised tensors to retain the canonical form. The product of the second SVD must be truncated as well, however, no loss of information will occur, as the Schmidt rank of the matrix $S$ will be at most $D$ following the first SVD. 
\end{enumerate}
Following the procedure will leave the MPS in position for application ofthe unitary $\hat{\mathcal{U}}^{[n+2 , n+3]}$. The efficiency of the tDMRG algorithm also depends on the sequence in which bonds are evolved. A simple, yet effective way is iterating from left to right when evolving even bonds, while iterating right to left when evolving odd bonds. Thereby, the centered cite of the mixed-canonical form is moved continuously through the MPS, rather than having to be reset when reaching the end of the system.\\

Although the tDMRG algorithm is a very powerful algorithm, an even higher efficiency can be achieved when tailoring the algorithm to the problem. In this case the problem is optimal control of the Superfluid to Mott-Insulator transition. Thus, the Hamiltonian contains both nearest-neighbour and on-site terms. Furthermore, the Hamiltonian is time dependent, and it is continuously modified in the process of searching for optimal control parameters. The following algorithm is a modification of the tDMRG algorithm, which accommodates the requirements of performing optimal control.


\section{Modified Time Evolution Algorithm for Optimal Control}
\label{sec:modTMDRG}
In order to efficiently conduct optimal control of a Bose-Hubbard system, a slightly modified version of the tDMRG algorithm was employed. As the Hamiltonian is changing with every time step, one has to account for the time spent exponentiating the operators when considering the runtime of the algorithm. A general operator $\hat{W}$ can be exponentiated through the series expansion
\begin{equation}
	\exp \left( \hat{W} \right) = \sum_{k = 0}^{\infty} \frac{\hat{W}^k}{k!} = \hat{\mathds{1}} + \hat{W} \Bigl(  \hat{\mathds{1}} + \frac{\hat{W}}{2} \Bigl( \hat{\mathds{1}} + \frac{\hat{W}}{3} \Bigl( \ldots
\label{eq:exponentialSeries}
\end{equation}
The number of terms needed in the expansion to accurately describe the exponentiation depends on the operator. Performing the exponentiation through a series expansion is a relatively expensive operator. Therefore, it is crucial to find an easier way of constructing the time evolution operator.
One method is by considering the form of the Bose-Hubbard Hamiltonian. The most natural choice of control parameter is the lattice depth, $V_0$, as it is controllable experimentally. The lattice depth determines both the tunneling matrix element, $J$ (eq. \eqref{eq:BHparamJ}), and the interaction matrix element, $U$ (eq. \eqref{eq:BHparamU}), and has served as control parameter in other studies CITE.   
Unfortunately exponentiating the hopping terms of the Bose-Hubbard Hamiltonian was relatively high. Therefore, it was concluded that keeping $J$ fixed and using $U$ as the control parameter was the better option. Due to the diagonal form of the number operator, $\hat{n}_i$, the exponentiation of the interaction term can be built directly without the need for the series expansion of eq. \eqref{eq:exponentialSeries}.
However, simply exponentiating the different terms of the Bose-Hubbard Hamiltonian separately is not possible, as the operators do not commute. Therefore, one must expand the time evolution operator into its components through the Suzuki-Trotter expansion. To second order the Suzuki-Trotter expansion reads
\begin{equation}
	\exp\left(  ( \hat{V} + \hat{W}  ) \delta \right) = \exp\left(  \hat{V} \delta /2  \right) \exp\left(  \hat{W} \delta   \right) \exp\left(  \hat{V} \delta /2  \right) + O(\delta^3) \; . \label{eq:SuzukiTrotter}
\end{equation}
Once again, the error is due to the non-commutativity of operators. Thus, the time evolution operator can be divided into a sequence of tensors, where
\begin{align}
	\hat{\mathcal{U}}_{J}^{[i,i+1]} (\Delta t) &= \exp \left( -i J ( \hat{a}_{i}^{\dag} \hat{a}_{i+1} + \hat{a}_{i+1}^{\dag} \hat{a}_{i} ) \Delta t \right) \\
	\hat{\mathcal{U}}_{U}^{[i]} (\Delta t /2) &= \exp \left( -i \frac{U}{2} \hat{n}_i (\hat{n}_i -1) \Delta t /2 \right) \; .
\end{align}
\begin{figure}[h!]
	\centering
	\input{Diagrams/ModifiedTDMRG.tex}
	\caption{\textit{Tensor diagram depicting a single time step of the modified rDMRG algorithm. The time evolution operator has been subjected to a Suzuki-Trotter expansion as detailed in eq. \eqref{eq:SuzukiTrotter}. The tensors of the upper part of the network are contracted with the MPS while sweeping from left to right, whereas the lower part is applied with a right-to-left sweep.}}
	\label{fig:ModifiedTEBD}
\end{figure}
A single time step, $\Delta t$, using the expanded operator is represented diagrammatically in figure \ref{fig:ModifiedTEBD}. At first glance, the tensor network resulting from the Suzuki-Trotter expansion may seem rather extensive, however, it can be contracted in a very efficient manner. The upper part of the network is contracted in a left-to-right sweeping manner, where the position of the center cite, and thereby the normalisation of the MPS, is pushed to the right following each step. Likewise, the lower part of the network is contracted though a right-to-left sweep such that the MPS returns to its original form centered on the first site after applying the final operator. Thereby, the MPS is immediately ready for the subsequent time-propagation.\\
\begin{figure}[h!]
\centering % <-- add this
\begin{subfigure}[b]{0.4\textwidth}
	\caption{}  
  	\input{Diagrams/TrotterStep1.tex}
\end{subfigure}
\hspace{10mm}
\begin{subfigure}[b]{0.4\textwidth}
	\caption{}    
  	\input{Diagrams/TrotterStep2.tex}
\end{subfigure}
\\ % <-- add this
\vspace{5mm}
\begin{subfigure}[b]{0.4\textwidth}
	\caption{}    	
  	\input{Diagrams/TrotterStep4.tex}
\end{subfigure}
\hspace{10mm}
\begin{subfigure}[b]{0.4\textwidth}
	\caption{}  
  	\input{Diagrams/TrotterStep6.tex}
\end{subfigure}
\caption{\textit{Sequence of contractions for modified tDMRG algorithm during left to right sweep. Step \textbf{(i)}: MPS is centered on site 1. Tensors $M^{[1]}$ and $M^{[2]}$ are contracted. Step \textbf{(ii)}: Two-site tensor, $\Theta$, is contracted with operators in numbered sequence. The propagated two-site tensor is split using an SVD in step \textbf{(iii)}, followed by a contraction to the right. Lastly, in step \textbf{(iv)}, the two-site tensor of $M^{[2]}$ and $M^{[3]}$ is split using another SVD, whereby the center (and thereby the normalisation) is pushed to site 3.}}
\label{fig:TEBDContraction}
\end{figure}
The sequence of contractions of the left-to-right sweep is shown in figure \ref{fig:TEBDContraction}. The MPS is initially centered on the first tensor, while its remaining tensors are all right-normalised. By contracting the bonds marked with a bold line, the operators are efficiently applied to the MPS. In step (iii) the two-site tensor, $\Theta$, is split using an SVD, where the bond dimension of the tensors is truncated. This is crucial in order to maintain a reduced dimensionality, which would otherwise result in a significant increase in contraction time. In the final step (iv), the central cite of the MPS is moved to the start of the next two-site operator through another site merge and subsequent SVD. This step is exactly as in the original tDMRG algorithm. Thereby the normalisation of the MPS is "pushed" to the right and contained in a single site, which makes it easy to deal with in the end of the time evolution step.\\
As the center reaches the end of the MPS, the direction of the sweep is reversed. The right-to-left sweep is very similar to the sequence described above. The main difference is in the order of contractions, as the $\hat{\mathcal{U}}_{J}^{[i,i+1]} (\Delta t)$-operator is applied before the $\hat{\mathcal{U}}_{U}^{[i]} (\Delta t /2)$-operator. As the sweep, and thereby the central cite, reaches the first site of the MPS, the central site is divided by its norm. Thereby the MPS is normalised and in the same configuration as before the time step. Thus, further propagations can be performed readily.\\ 
Additional precision is achieved when evaluating the potential at the beginning and end points of the time interval CITE DANIEL STECK. Thus, the left-to-right sweep applies the operator $\hat{\mathcal{U}}_{U(t)}^{[i]} (\Delta t /2)$, while the right-to-left sweep applies $\hat{\mathcal{U}}_{U(t + \Delta t)}^{[i]} (\Delta t /2)$.\\

The Suzuki-Trotter expansion \eqref{eq:SuzukiTrotter} does not determine the ordering of the operators. Thus, an alternative algorithm exists, where the half-step is taken through the $\hat{\mathcal{U}}_{J}^{[i,i+1]}$ operator. However, applying the two-site operators are in general more time consuming than applying two single-site operator.
A comparison between the run-times of various time-evolution algorithms in shown in FIGURE. The MPO-based algorithm builds the propagator using the ITensor library methods following \cite{Pollmann2015}, whereby the resulting MPO is applied to the MPS according to eq. \eqref{eq:optBracketsMPO}. This method has an error of order $O(\Delta t ^2)$, which is less accurate than the second-order Trotter expansion.
The fast version of the U-split algorithm employs a density-matrix decomposition to split the two-site tensors, which is slightly faster than the conventional SVD \cite{schollwock}. 

 
 To properly gauge the accuracy of this time evolution operator, it must be compared to the more reliable approach of direct diagonalisation.


\section{Numerical Comparison of Time Evolution Algorithms}